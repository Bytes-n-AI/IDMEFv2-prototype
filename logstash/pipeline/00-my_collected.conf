input {
  tcp {
    port => "${LISTEN_SYSLOG}"
    dns_reverse_lookup_enabled => false
    add_field                  => {
      "[@metadata][source]" => "syslog-tcp"
    }
  }
  udp {
    port => "${LISTEN_SYSLOG}"
    receive_buffer_bytes => 16777216
    workers => 4
    add_field            => {
      "[@metadata][source]" => "syslog-udp"
    }
    source_ip_fieldname  => "[@metadata][input][tcp][source][ip]"
  }
}

filter {
  grok {
    match               => {
      'message' => [
        # Cisco-related formats
        #   <pri>year timestamp.msec tz: ip hostname seqno: %event_code: message
        #   <pri>seqno: uptime: %event_code: message
        #
        # where pri, year, timestamp, msec, tz, ip, hostname, seqno & uptime may be omitted (depending on device configuration)
        #   logging facility
        #   logging hostname
        #   service timestamps log datetime msec show-timezone year
        #   service timestamps log uptime
        #
        # Listed before other patterns to avoid conflicts.
        # Even though the pattern accepts an optional timezone, its content is not used when parsing the timestamp.
        '^(?:<%{NONNEGINT:[Attachment][RawLog][Content][log][syslog][priority]:int}>)?%{SYSLOGTIMESTAMP:[@metadata][timestamp]} (?:%{WORD}: )?(?:%{IP:[Attachment][RawLog][Content][host][ip]})?%{SYSLOGHOST:[Attachment][RawLog][Content][host][hostname]} (?:%{NONNEGINT}: )?%%{DATA:[Attachment][RawLog][Content][event][code]}: %{GREEDYDATA:[Attachment][RawLog][Content][message]}',
        '^(?:<%{NONNEGINT:[Attachment][RawLog][Content][log][syslog][priority]:int}>)?(?:%{NONNEGINT}: )?%{WORD}: %%{DATA:[Attachment][RawLog][Content][event][code]}: %{GREEDYDATA:[Attachment][RawLog][Content][message]}',

        # RFC 5424
        #   <pri>version timestamp hostname app-name procid msgid structured-data msg
        #   <pri>version timestamp hostname app-name procid msgid structured-data
        '^<%{NONNEGINT:[Attachment][RawLog][Content][log][syslog][priority]:int}>%{POSINT} (?:-|%{TIMESTAMP_ISO8601:[@metadata][timestamp]}) (?:-|%{HOSTNAME:[Attachment][RawLog][Content][host][hostname]}) %{NOTSPACE:[Attachment][RawLog][Content][process][name]} (?:-|%{NONNEGINT:[Attachment][RawLog][Content][process][pid]:int}) %{NOTSPACE:[Attachment][RawLog][Content][event][id]} (?:-|(?<SD>(?:\[(?:\\.|[!-\\\\^-~ ])+\])+))(?: %{GREEDYDATA:[Attachment][RawLog][Content][message]})?',

        # RFC 3164 (including CEF & LEEF) with several extensions
        #   <pri>timestamp hostname ip processname[pid]: message
        #   <pri>timestamp ip hostname processname[pid]: message
        #   <pri>timestamp iporhost processname[pid]: message
        #   <pri>timestamp iporhost: message
        #
        # The pattern allows the pri & pid fields to be omitted. It also accepts an optional ip field.
        # It accepts ISO 8601 dates/times and optional year/msecs fields for the RFC 3164 format.
        # It a single IP address or hostname is given, the processname & pid fields may be omitted entirely.
        '^(?:<%{NONNEGINT:[Attachment][RawLog][Content][log][syslog][priority]:int}>)?(?:%{SYSLOGTIMESTAMP:[@metadata][timestamp]}|%{TIMESTAMP_ISO8601:[@metadata][timestamp]}) %{HOSTNAME:[Attachment][RawLog][Content][host][hostname]} %{IP:[Attachment][RawLog][Content][host][ip]} %{PROG:[Attachment][RawLog][Content][process][name]}(?:\[%{POSINT:[Attachment][RawLog][Content][process][pid]:int}\])?: ?%{GREEDYDATA:[Attachment][RawLog][Content][message]}',
        '^(?:<%{NONNEGINT:[Attachment][RawLog][Content][log][syslog][priority]:int}>)?(?:%{SYSLOGTIMESTAMP:[@metadata][timestamp]}|%{TIMESTAMP_ISO8601:[@metadata][timestamp]}) %{IP:[Attachment][RawLog][Content][host][ip]} %{SYSLOGHOST:[Attachment][RawLog][Content][host][hostname]} %{PROG:[Attachment][RawLog][Content][process][name]}(?:\[%{POSINT:[Attachment][RawLog][Content][process][pid]:int}\])?: ?%{GREEDYDATA:[Attachment][RawLog][Content][message]}',
        '^(?:<%{NONNEGINT:[Attachment][RawLog][Content][log][syslog][priority]:int}>)?(?:%{SYSLOGTIMESTAMP:[@metadata][timestamp]}|%{TIMESTAMP_ISO8601:[@metadata][timestamp]}) (?:%{IP:[Attachment][RawLog][Content][host][ip]}|%{HOSTNAME:[Attachment][RawLog][Content][host][hostname]})(?: %{PROG:[Attachment][RawLog][Content][process][name]}(?:\[%{POSINT:[Attachment][RawLog][Content][process][pid]:int}\])?)?: ?%{GREEDYDATA:[Attachment][RawLog][Content][message]}'
      ]
    }
    pattern_definitions => {
        # Allow an optional "year" field, either before the RFC 3164 date/time or between the month's day & time parts.
        # Allow an optional "msec" field for sub-second time resolution.
        'SYSLOGTIMESTAMP' => '(?:(?:%{YEAR} )?%{MONTH} +%{MONTHDAY} %{TIME}(?:\.%{NONNEGINT})?|%{MONTH} +%{MONTHDAY} (?:%{YEAR} )?%{TIME)(?:\.%{NONNEGINT})?'
    }
    timeout_scope       => "event"
    ecs_compatibility   => "disabled"
  }

  if "_grokparsefailure" in [tags] or "_groktimeout" in [tags] {
    drop {}
  }

  # Parse STRUCTURED-DATA field from RFC 5424 compliant logs.
  # This also removes any Byte-Order-Mark that may be present.
  # Finally, this removes the [SD] field from the event.
  ruby {
    path          => "/usr/share/logstash/config/scripts/rfc5424.rb"
    script_params => {
      'source'            => '[SD]'
    }
  }

  if ![Attachment][RawLog][Content][process][name] {
    mutate {
      add_field => { '[Attachment][RawLog][Content][process][name]' => '-' }
    }
  } else if [Attachment][RawLog][Content][process][name] == "CEF" {
    # Jan 18 11:07:53 host CEF: 0|Citrix|NetScaler|NS10.0|APPFW|APPFW_STARTURL|6|src=10.217.253.78 spt=54711 requestMethod=GET request=http://vpx247.example.net/FFC/login_post.html?abc\=def msg=Disallow Illegal URL. cn1=465 cn2=535 cs1=profile1 cs2=PPE0 cs3=IliG4Dxp1SjOhKVRDVBXmqvAaIcA000 cs4=ALERT cs5=2012 act=not blocked
    ruby {
      init => "
        require 'logstash/codecs/cef'
        class CEF < LogStash::Codecs::CEF
          attr_reader :decode_mapping
          attr_reader :header_fields
        end
        @cef = CEF.new({'ecs_compatibility' => 'v1'})
      "
      code => "
        @cef.handle(event.get('[Attachment][RawLog][Content][message]')) do |ev|
          tags = ev.get('tags')
          if tags.nil? or !tags.to_a.contains('_cefparsefailure')
            # See generate_mappings! in https://github.com/logstash-plugins/logstash-codec-cef/blob/master/lib/logstash/codecs/cef.rb
            @cef.decode_mapping.each_key do |cefName|
              v = ev.get(cefName)
              unless v.nil?
                event.set('[Attachment][RawLog][Content][CEF]['+cefName+']', v)
              end
            end
            @cef.header_fields.each do |cefName|
              v = ev.get(cefName)
              unless v.nil?
                event.set('[Attachment][RawLog][Content][CEF]['+cefName+']', v)
              end
            end
          end
          break
        end
      "
    }
  }

  date {
    # Even though Joda-time / Java 8 are limited to milliseconds precision
    # additional decimals may still be matched by using the 'S' pattern.
    match     => [
      '[@metadata][timestamp]',
      'MMM dd yyyy HH:mm:ss.SSSSSS',
      'MMM dd yyyy HH:mm:ss.SSS',
      'MMM dd yyyy HH:mm:ss',
      'MMM  d yyyy HH:mm:ss.SSSSSS',
      'MMM  d yyyy HH:mm:ss.SSS',
      'MMM  d yyyy HH:mm:ss',
      'yyyy MMM dd HH:mm:ss.SSSSSS',
      'yyyy MMM dd HH:mm:ss.SSS',
      'yyyy MMM dd HH:mm:ss',
      'yyyy MMM  d HH:mm:ss.SSSSSS',
      'yyyy MMM  d HH:mm:ss.SSS',
      'yyyy MMM  d HH:mm:ss',
      'MMM dd HH:mm:ss.SSSSSS',
      'MMM dd HH:mm:ss.SSS',
      'MMM dd HH:mm:ss',
      'MMM  d HH:mm:ss.SSSSSS',
      'MMM  d HH:mm:ss.SSS',
      'MMM  d HH:mm:ss',
      'ISO8601'
    ]
    target    => "[Attachment][RawLog][Content][@timestamp]"

    add_field => {
      '[Attachment][RawLog][ContentType]'              => 'application/json'
      '[Attachment][RawLog][Content][host][ip]'        => '%{[@metadata][input][tcp][source][ip]}'
      '[Attachment][RawLog][Content][event][original]' => '%{message}'
      '[Attachment][RawLog][Content][event][created]'  => '%{@timestamp}'
    }
  }

  ruby {
    code => "
      # See RFC 3164 for the reason the default priority value is 13
      priority = (event.get('[Attachment][RawLog][Content][log][syslog][priority]') || 13)
      event.set('[Attachment][RawLog][Content][log][syslog][facility][code]', (priority / 8))
      event.set('[Attachment][RawLog][Content][log][syslog][severity][code]', (priority % 8))
    "

    add_field => {
      '[Attachment][RawLog][Content][event][provider]' => '%{[Attachment][RawLog][Content][process][name]}'
    }
  }

  # Extracts things that look like IP addresses, Email addresses and URIs
  # so CTI enrichment can analyze them.
  ruby {
    path          => "/usr/share/logstash/config/scripts/extraction.rb"
    script_params => {
      'source' => '[Attachment][RawLog][Content][message]'
    }
  }

  if [Attachment][RawLog][Content][host][hostname] {
    mutate {
      add_field => {
        '[Sensor][0][Hostname]' => '%{[Attachment][RawLog][Content][host][hostname]}'
      }
    }
  }

  translate {
    source           => '[Attachment][RawLog][Content][process][name]'
    target           => '[Attachment][RawLog][Content][service][type]'
    fallback         => '%{[Attachment][RawLog][Content][process][name]}'
    dictionary => {
      'apache' => 'httpd'
    }

    add_field => {
      '[Sensor][0][IP]'       => '%{[@metadata][input][tcp][source][ip]}'
      '[Sensor][0][Model]'    => '%{[Attachment][RawLog][Content][service][type]}'
      '[Sensor][0][Name]'     => '%{[Attachment][RawLog][Content][service][type]}'
    }
  }

  translate {
    source      => '[Attachment][RawLog][Content][log][syslog][severity][code]'
    target      => '[Attachment][RawLog][Content][log][syslog][severity][name]'
    dictionary  => {
      '0' => 'Emergency'
      '1' => 'Alert'
      '2' => 'Critical'
      '3' => 'Error'
      '4' => 'Warning'
      '5' => 'Notice'
      '6' => 'Informational'
      '7' => 'Debug'
    }
  }

  translate {
    source      => '[Attachment][RawLog][Content][log][syslog][facility][code]'
    target      => '[Attachment][RawLog][Content][log][syslog][facility][name]'
    fallback    => 'Unknown'
    dictionary  => {
       '0' => 'kernel'
       '1' => 'user-level'
       '2' => 'mail'
       '3' => 'system'
       '4' => 'security/authorization'
       '5' => 'syslogd'
       '6' => 'line printer'
       '7' => 'network news'
       '8' => 'UUCP'
       '9' => 'clock'
      '10' => 'security/authorization'
      '11' => 'FTP'
      '12' => 'NTP'
      '13' => 'log audit'
      '14' => 'log alert'
      '15' => 'clock'
      '16' => 'local0'
      '17' => 'local1'
      '18' => 'local2'
      '19' => 'local3'
      '20' => 'local4'
      '21' => 'local5'
      '22' => 'local6'
      '23' => 'local7'
    }
  }

  prune {
    whitelist_names => [
      # Top-level IDMEF attributes
      'Version',
      'ID',
      'Entity',
      'Category',
      'ext-Category',
      'Cause',
      'Description',
      'Status',
      'Priority',
      'Confidence',
      'Note',
      'CreateTime',
      'StartTime',
      'EndTime',
      'AltNames',
      'AltCategory',
      'Ref',
      'CorrelID',
      'AggrCondition',
      'PredID',
      'RelID',

      # IDMEF classes
      'Analyzer',
      'Sensor',
      'Source',
      'Target',
      'Vector',
      'Attachment',

      # Tags for internal use
      'tags'
    ]
  }

  ruby {
    path          => "/usr/share/logstash/config/scripts/match.rb"
    script_params => { "rules" => "/usr/share/logstash/config/rules.yml" }
  }

  ruby {
    code => "
      # Convert hashes back to lists
      [ '[Ref]', '[Sensor]' ].each do |k|
        v = event.get(k)
        if v.is_a?(Hash) then
          event.set(k, v.values)
        end
      end
    "
  }

  prune {
    whitelist_names => [
      # Top-level IDMEF attributes
      'Version',
      'ID',
      'Entity',
      'Category',
      'ext-Category',
      'Cause',
      'Description',
      'Status',
      'Priority',
      'Confidence',
      'Note',
      'CreateTime',
      'StartTime',
      'EndTime',
      'AltNames',
      'AltCategory',
      'Ref',
      'CorrelID',
      'AggrCondition',
      'PredID',
      'RelID',

      # IDMEF classes
      'Analyzer',
      'Sensor',
      'Source',
      'Target',
      'Vector',
      'Attachment'
    ]
  }
}

output {
  kafka {
    bootstrap_servers => "${BOOTSTRAP_SERVER}"
    topic_id => "${TOPIC_COLLECTED}"
    codec => json
  }
}
output {
  kafka {
    bootstrap_servers => "${BOOTSTRAP_SERVER}"
    topic_id => "${TOPIC_COLLECTED}2"
    codec => json
  }
}
